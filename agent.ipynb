{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025/6/25\n",
    "# zhangzhong\n",
    "# https://python.langchain.com/docs/tutorials/agents/\n",
    "# TODO: 今天把RAG部分给看完就行了\n",
    "# https://python.langchain.com/docs/tutorials/rag/\n",
    "# https://python.langchain.com/docs/tutorials/qa_chat_history/\n",
    "# 把这些给看完就行 大概2个小时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain supports the creation of agents, or systems that use LLMs as reasoning engines \n",
    "# to determine which actions to take and the inputs necessary to perform the action. \n",
    "# After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, \n",
    "# or whether it is okay to finish. This is often achieved via tool-calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import relevant functionality\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# # I need to find a better search engine\n",
    "# # https://python.langchain.com/docs/integrations/tools/#search\n",
    "# # tavily 有免费额度 还是用吧 毕竟这是一个tutorial\n",
    "# from langchain_tavily import TavilySearch\n",
    "# from langgraph.checkpoint.memory import MemorySaver # you chould change to persistance storage, such as redis, sqlite, etc.\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# # Create the agent\n",
    "# memory = MemorySaver()\n",
    "# model = init_chat_model(\"anthropic:claude-3-5-sonnet-latest\")\n",
    "# search = TavilySearch(max_results=2)\n",
    "# tools = [search]\n",
    "# agent_executor = create_react_agent(model, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is the weather in SF', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1750821010, 'localtime': '2025-06-24 20:10'}, 'current': {'last_updated_epoch': 1750820400, 'last_updated': '2025-06-24 20:00', 'temp_c': 13.9, 'temp_f': 57.0, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 10.7, 'wind_kph': 17.3, 'wind_degree': 251, 'wind_dir': 'WSW', 'pressure_mb': 1017.0, 'pressure_in': 30.03, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 83, 'cloud': 75, 'feelslike_c': 12.5, 'feelslike_f': 54.5, 'windchill_c': 10.6, 'windchill_f': 51.1, 'heatindex_c': 12.0, 'heatindex_f': 53.6, 'dewpoint_c': 11.1, 'dewpoint_f': 51.9, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 15.7, 'gust_kph': 25.3}}\", 'score': 0.9592684, 'raw_content': None}, {'title': 'Wednesday, June 25, 2025. San Francisco, CA - Weather Forecast', 'url': 'https://weathershogun.com/weather/usa/ca/san-francisco/480/june/2025-06-25', 'content': 'San Francisco, California weather forecast for Wednesday, June 25, 2025. Get the latest on temperature, precipitation, wind speed, and UV. ... °F °C Today Tomorrow Hourly 7 days 30 days June San Francisco, California Weather: Wednesday, June 25, 2025. Sunny weather, clear skies and sunny weather. Day 66', 'score': 0.9242583, 'raw_content': None}], 'response_time': 1.2}\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search = TavilySearch(max_results=2)\n",
    "search_results = search.invoke(\"What is the weather in SF\")\n",
    "print(search_results)\n",
    "# If we want, we can create other tools.\n",
    "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/integrations/chat/deepseek/\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "model = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! 😊 How can I help you today?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hi!\"\n",
    "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "response.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to enable that we use .bind_tools to give the language model knowledge of these tools\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message content: \n",
      "\n",
      "Tool calls: [{'name': 'tavily_search', 'args': {'query': 'current weather in San Francisco', 'search_depth': 'basic'}, 'id': 'call_0_4d97f197-c2ed-4e13-8bde-12f8572dbeb8', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"Search for the weather in SF\"\n",
    "response = model_with_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
    "\n",
    "print(f\"Message content: {response.text()}\\n\")\n",
    "print(f\"Tool calls: {response.tool_calls}\")\n",
    "\n",
    "# important!!!\n",
    "# We can see that there's now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\n",
    "# This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent.\n",
    "# 大模型根据我们的提问，决定要调用search tool\n",
    "# 然后他通过response告诉了我们这个信息\n",
    "# 我们拿着大模型的返回值去调用search tool\n",
    "# 然后把search tool的返回值在返回给大模型\n",
    "# 然后大模型在整理一份回答给我们\n",
    "# 这就是一次简单的function calling的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/tutorials/agents/#create-the-agent\n",
    "# langgraph is backed by a low-level, highly controllable API in case you want to modify the agent logic.\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(model, tools)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today? 😊\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"Hi!\"}\n",
    "response = agent_executor.invoke({\"messages\": [input_message]})\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Search for the weather in SF\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_a3d32716-9b3e-449b-a186-7350fde39a65)\n",
      " Call ID: call_0_a3d32716-9b3e-449b-a186-7350fde39a65\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "    search_depth: basic\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"current weather in San Francisco\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Weather in San Francisco\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1750824341, 'localtime': '2025-06-24 21:05'}, 'current': {'last_updated_epoch': 1750824000, 'last_updated': '2025-06-24 21:00', 'temp_c': 13.9, 'temp_f': 57.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.8, 'wind_kph': 15.8, 'wind_degree': 247, 'wind_dir': 'WSW', 'pressure_mb': 1017.0, 'pressure_in': 30.03, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 83, 'cloud': 75, 'feelslike_c': 12.6, 'feelslike_f': 54.8, 'windchill_c': 10.5, 'windchill_f': 50.9, 'heatindex_c': 11.9, 'heatindex_f': 53.4, 'dewpoint_c': 11.0, 'dewpoint_f': 51.8, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 14.5, 'gust_kph': 23.3}}\", \"score\": 0.9880845, \"raw_content\": null}, {\"title\": \"Weather in San Francisco in June 2025\", \"url\": \"https://world-weather.info/forecast/usa/san_francisco/june-2025/\", \"content\": \"Detailed ⚡ San Francisco Weather Forecast for June 2025 - day/night 🌡️ temperatures, precipitations - World-Weather.info. Add the current city. Search. Weather; Archive; Weather Widget °F. World; United States; California; Weather in San Francisco; ... 25 +64° +54° 26 +64° +54° 27\", \"score\": 0.8729662, \"raw_content\": null}], \"response_time\": 1.97}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in San Francisco is partly cloudy with a temperature of 57°F (13.9°C). The wind is blowing from the WSW at 9.8 mph (15.8 kph), and the humidity is at 83%. The feels-like temperature is 54.8°F (12.6°C).\n",
      "\n",
      "For more details, you can check [Weather API](https://www.weatherapi.com/).\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"Search for the weather in SF\"}\n",
    "response = agent_executor.invoke({\"messages\": [input_message]})\n",
    "\n",
    "for message in response[\"messages\"]:\n",
    "    message.pretty_print()\n",
    "# 可以很明显的看到，所有的消息都是一次性输出出来的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Search for the weather in SF\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_0_6072d3ee-cda3-46db-9d60-6f22c1282267)\n",
      " Call ID: call_0_6072d3ee-cda3-46db-9d60-6f22c1282267\n",
      "  Args:\n",
      "    query: current weather in San Francisco\n",
      "    search_depth: basic\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"current weather in San Francisco\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Weather in San Francisco\", \"url\": \"https://www.weatherapi.com/\", \"content\": \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1750824341, 'localtime': '2025-06-24 21:05'}, 'current': {'last_updated_epoch': 1750824000, 'last_updated': '2025-06-24 21:00', 'temp_c': 13.9, 'temp_f': 57.0, 'is_day': 0, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/night/116.png', 'code': 1003}, 'wind_mph': 9.8, 'wind_kph': 15.8, 'wind_degree': 247, 'wind_dir': 'WSW', 'pressure_mb': 1017.0, 'pressure_in': 30.03, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 83, 'cloud': 75, 'feelslike_c': 12.6, 'feelslike_f': 54.8, 'windchill_c': 10.5, 'windchill_f': 50.9, 'heatindex_c': 11.9, 'heatindex_f': 53.4, 'dewpoint_c': 11.0, 'dewpoint_f': 51.8, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 14.5, 'gust_kph': 23.3}}\", \"score\": 0.9086151, \"raw_content\": null}, {\"title\": \"Weather in San Francisco in June 2025 - Detailed Forecast\", \"url\": \"https://www.easeweather.com/north-america/united-states/california/city-and-county-of-san-francisco/san-francisco/june\", \"content\": \"Official Weather Alert ⚠️; Coastal Flood Advisory - See hour by hour. Temperatures; Until now, June 2025 in San Francisco has been significantly cooler than historical averages by -5.4 ° F, with average temperature of 13.4 ° F.. The forecast for the upcoming days in San Francisco predicts a temperature of 17.1 ° F, which is slightly above the historical average.\", \"score\": 0.8868231, \"raw_content\": null}], \"response_time\": 2.0}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current weather in San Francisco is partly cloudy with a temperature of 57°F (13.9°C). The wind is blowing from the WSW at 9.8 mph (15.8 kph), and the humidity is at 83%. The feels-like temperature is around 54.8°F (12.6°C).\n",
      "\n",
      "For more details, you can check [Weather API](https://www.weatherapi.com/).\n"
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/tutorials/agents/#streaming-messages\n",
    "# If the agent executes multiple steps, this may take a while. \n",
    "# To show intermediate progress, we can stream back messages as they occur.\n",
    "\n",
    "for step in agent_executor.stream({\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()\n",
    "    # 看来每个step还是会返回所有的消息，所以需要拿最后一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is partly cloudy with a temperature of 57°F (13.9°C). The wind is blowing from the WSW at 9.8 mph (15.8 kph), and the humidity is at 83%. The feels-like temperature is 54.8°F (12.6°C).\n",
      "\n",
      "For more details, you can check [Weather API](https://www.weatherapi.com/)."
     ]
    }
   ],
   "source": [
    "# https://python.langchain.com/docs/tutorials/agents/#streaming-tokens\n",
    "for step, metadata in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, stream_mode=\"messages\"\n",
    "):\n",
    "    # TODO: 不知道该怎么把这两种模式结合起来\n",
    "    # 既展示agent的决策过程，又可以stream token\n",
    "    if metadata[\"langgraph_node\"] == \"agent\":\n",
    "        print(step.text(), end=\"\")\n",
    "    elif metadata[\"langgraph_node\"] == \"tool\":\n",
    "        print(f\"\\nTool call: {step.tool_call_id}\")\n",
    "        print(f\"Tool name: {step.tool_name}\")\n",
    "        print(f\"Tool input: {step.tool_input}\")\n",
    "        print(f\"Tool output: {step.tool_output}\")\n",
    "        print(f\"Tool error: {step.tool_error}\")\n",
    "        print(f\"Tool result: {step.tool_result}\")\n",
    "        print(f\"Tool result: {step.tool_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/docs/tutorials/agents/#adding-in-memory\n",
    "# As mentioned earlier, this agent is stateless\n",
    "# This means it does not remember previous interactions.\n",
    "# pass a checkpointer, and the thread id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, I'm Bob!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi, Bob! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"Hi, I'm Bob!\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='Your', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' name', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='Bob', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='**', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' You', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=\"'ve\", additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' mentioned', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' it', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' few', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' times', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' now', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='.', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' 😄', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' Is', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' there', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' anything', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' else', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=\"'d\", additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' like', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' chat', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' need', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' help', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=',', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' Bob', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49'), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache'}, id='run--d67a9d19-809d-4971-83cb-fc69cb341f49', usage_metadata={'input_tokens': 1319, 'output_tokens': 35, 'total_tokens': 1354, 'input_token_details': {'cache_read': 1280}, 'output_token_details': {}}), {'thread_id': 'abc123', 'langgraph_step': 10, 'langgraph_node': 'agent', 'langgraph_triggers': ('branch:to:agent',), 'langgraph_path': ('__pregel_pull', 'agent'), 'langgraph_checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'checkpoint_ns': 'agent:06c51c7a-15a0-feba-b69b-ff359cdfe82f', 'ls_provider': 'openai', 'ls_model_name': 'deepseek-chat', 'ls_model_type': 'chat', 'ls_temperature': 0.0, 'LANGSMITH_PROJECT': '\"translation\" # or any other project name', 'LANGSMITH_TRACING': 'true', 'revision_id': '508e989-dirty'})\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [input_message]}, config, stream_mode=\"messages\"\n",
    "):\n",
    "    print(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
