{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602dab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2025/12/27\n",
    "# zhangzhong\n",
    "# https://docs.langchain.com/oss/python/langgraph/interrupts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62f03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interrupts allow you to pause graph execution at specific points and wait for external input before continuing\n",
    "# human in the loop\n",
    "# When an interrupt is triggered, LangGraph saves the graph state using its persistence layer and waits indefinitely until you resume execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1334bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interrupt 有点像coroutine await \n",
    "# - Interrupts work by calling the interrupt() function at any point in your graph nodes.\n",
    "# - you resume execution by re-invoking the graph using Command, which then becomes the return value of the interrupt() call from inside the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abb9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个东西可能和我想的收集用户输入的方式不一样，\n",
    "# - static breakpoint: 我想的功能应该只需要写一个单独的node就可以了 , condition on my graph branches\n",
    "# - dynamic breakpoint: 但是interupt可以在node的内部中断，是不是一般情况下用不到这个？\n",
    "\n",
    "# Unlike static breakpoints (which pause before or after specific nodes), interrupts are dynamic\n",
    "# —they can be placed anywhere in your code and can be conditional based on your application logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b139754",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'State' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interrupt\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapproval_node\u001b[39m(state: \u001b[43mState\u001b[49m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Pause and ask for approval\u001b[39;00m\n\u001b[32m      5\u001b[39m     approved = interrupt(\u001b[33m\"\u001b[39m\u001b[33mDo you approve this action?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# When you resume, Command(resume=...) returns that value here\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'State' is not defined"
     ]
    }
   ],
   "source": [
    "## Pause using interupt\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "def approval_node(state: State):\n",
    "    # Pause and ask for approval\n",
    "\n",
    "\n",
    "    # When you call interrupt, here’s what happens:\n",
    "    # 1. [Graph execution gets suspended] at the exact point where interrupt is called\n",
    "    # 2. State is saved using the checkpointer so execution can be resumed later, In production, this should be a persistent checkpointer (e.g. backed by a database)\n",
    "    # ??? 3. Value is returned to the caller under __interrupt__; it can be any JSON-serializable value (string, object, array, etc.)\n",
    "    # # Graph waits indefinitely until you resume execution with a response\n",
    "    # # Response is passed back into the node when you resume, becoming the return value of the interrupt() call\n",
    "    approved = interrupt(\"Do you approve this action?\")\n",
    "\n",
    "    # what do you mean?\n",
    "    # When you resume, Command(resume=...) returns that value here\n",
    "    return {\"approved\": approved}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8584903",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resuming interrupts\n",
    "# After an interrupt pauses execution, you resume the graph by invoking it again with a Command that contains the resume value.\n",
    "\n",
    "# No! this is not a good idea!\n",
    "# Key points about resuming:\n",
    "# You must use the same thread ID when resuming that was used when the interrupt occurred\n",
    "# The value passed to Command(resume=...) becomes the return value of the interrupt call\n",
    "# The node restarts from the beginning of the node where the interrupt was called when resumed, so any code before the interrupt runs again\n",
    "# You can pass any JSON-serializable value as the resume value\n",
    "\n",
    "## 我觉得human in the loop 的理念是好的，但是总觉得这个interupt设计的不好\n",
    "\n",
    "from langgraph.types import Command\n",
    "\n",
    "# Initial run - hits the interrupt and pauses\n",
    "# thread_id is the persistent pointer (stores a stable ID in production)\n",
    "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "result = graph.invoke({\"input\": \"data\"}, config=config) # this is the caller\n",
    "\n",
    "# 那么这么interrupt怎么和现在的聊天api结合呢？ 感觉还是非常的不方便啊！！！\n",
    "# Check what was interrupted\n",
    "# __interrupt__ contains the payload that was passed to interrupt()\n",
    "print(result[\"__interrupt__\"])\n",
    "# > [Interrupt(value='Do you approve this action?')]\n",
    "\n",
    "# Resume with the human's response\n",
    "# The resume payload becomes the return value of interrupt() inside the node\n",
    "graph.invoke(Command(resume=True), config=config)\n",
    "\n",
    "\n",
    "# the call approved = interrupt(\"Do you approve this action?\") suspends the graph and \n",
    "# returns the __interrupt__ payload to the caller.\n",
    "#  When you resume that same thread with Command(resume=True), \n",
    "# !!! execution restarts from the beginning of the node\n",
    "# and the call returns the resume value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea083df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Approve or reject\n",
    "# For example, you might want to ask a human to approve an API call, a database change, or any other important decision.\n",
    "\n",
    "def approval_node(state: State) -> Command[Literal[\"proceed\", \"cancel\"]]:\n",
    "    # 可以看到这些interrupt都是在函数的最开头，避免那个execution restarts from the beginning of the node的问题\n",
    "    # Pause execution; payload shows up under result[\"__interrupt__\"]\n",
    "    is_approved = interrupt({\n",
    "        \"question\": \"Do you want to proceed with this action?\",\n",
    "        \"details\": state[\"action_details\"]\n",
    "    })\n",
    "\n",
    "    # Route based on the response\n",
    "    if is_approved:\n",
    "        return Command(goto=\"proceed\")  # Runs after the resume payload is provided\n",
    "    else:\n",
    "        return Command(goto=\"cancel\")\n",
    "\n",
    "\n",
    "# 从interrupt的问题中提取出答案，不就是structured output吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interrupt(value={'question': 'Approve this action?', 'details': 'Transfer $500'}, id='216b11498506780b705177567fbe089c')]\n",
      "approved\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal, Optional, TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "class ApprovalState(TypedDict):\n",
    "    action_details: str\n",
    "    status: Optional[Literal[\"pending\", \"approved\", \"rejected\"]]\n",
    "\n",
    "\n",
    "def approval_node(state: ApprovalState) -> Command[Literal[\"proceed\", \"cancel\"]]:\n",
    "    # Expose details so the caller can render them in a UI\n",
    "    # 所以interrupt的参数值就是graph.invoke在中断的时候的返回值\n",
    "    decision = interrupt({\n",
    "        \"question\": \"Approve this action?\",\n",
    "        \"details\": state[\"action_details\"],\n",
    "    })\n",
    "\n",
    "    # Route to the appropriate node after resume\n",
    "    return Command(goto=\"proceed\" if decision else \"cancel\")\n",
    "\n",
    "\n",
    "def proceed_node(state: ApprovalState):\n",
    "    return {\"status\": \"approved\"}\n",
    "\n",
    "\n",
    "def cancel_node(state: ApprovalState):\n",
    "    return {\"status\": \"rejected\"}\n",
    "\n",
    "\n",
    "builder = StateGraph(ApprovalState)\n",
    "builder.add_node(\"approval\", approval_node)\n",
    "builder.add_node(\"proceed\", proceed_node)\n",
    "builder.add_node(\"cancel\", cancel_node)\n",
    "builder.add_edge(START, \"approval\")\n",
    "builder.add_edge(\"proceed\", END)\n",
    "builder.add_edge(\"cancel\", END)\n",
    "\n",
    "# Use a more durable checkpointer in production\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"approval-123\"}}\n",
    "initial = graph.invoke(\n",
    "    {\"action_details\": \"Transfer $500\", \"status\": \"pending\"},\n",
    "    config=config,\n",
    ")\n",
    "# 我们是需要拿着这个问题，去问人类，然后从人类的回答中，结构化提取出我们需要的类型，再传给interrupt函数的\n",
    "print(initial[\"__interrupt__\"])  # -> [Interrupt(value={'question': ..., 'details': ...})]\n",
    "\n",
    "# Resume with the decision; True routes to proceed, False to cancel\n",
    "resumed = graph.invoke(Command(resume=True), config=config)\n",
    "print(resumed[\"status\"])  # -> \"approved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comman patterns\n",
    "\n",
    "# Approval workflows: Pause before executing critical actions (API calls, database changes, financial transactions)\n",
    "# Review and edit: Let humans review and modify LLM outputs or tool calls before continuing\n",
    "# Interrupting tool calls: Pause before executing tool calls to review and edit the tool call before execution\n",
    "# Validating human input: Pause before proceeding to the next step to validate human input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461840a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Approve or reject\n",
    "\n",
    "from typing import Literal\n",
    "from langgraph.types import interrupt, Command\n",
    "\n",
    "def approval_node(state: State) -> Command[Literal[\"proceed\", \"cancel\"]]:\n",
    "    # Pause execution; payload shows up under result[\"__interrupt__\"]\n",
    "    is_approved = interrupt({\n",
    "        \"question\": \"Do you want to proceed with this action?\",\n",
    "        \"details\": state[\"action_details\"]\n",
    "    })\n",
    "\n",
    "    # Route based on the response\n",
    "    if is_approved:\n",
    "        return Command(goto=\"proceed\")  # Runs after the resume payload is provided\n",
    "    else:\n",
    "        return Command(goto=\"cancel\")\n",
    "    \n",
    "# When you resume the graph, pass true to approve or false to reject:\n",
    "# To approve\n",
    "graph.invoke(Command(resume=True), config=config)\n",
    "\n",
    "# To reject\n",
    "graph.invoke(Command(resume=False), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e48c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Review and edit state\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "def review_node(state: State):\n",
    "    # Pause and show the current content for review (surfaces in result[\"__interrupt__\"])\n",
    "    edited_content = interrupt({\n",
    "        \"instruction\": \"Review and edit this content\",\n",
    "        \"content\": state[\"generated_text\"]\n",
    "    })\n",
    "\n",
    "    # Update the state with the edited version\n",
    "    return {\"generated_text\": edited_content}\n",
    "\n",
    "# ...\n",
    "\n",
    "graph.invoke(\n",
    "    Command(resume=\"The edited and improved text\"),  # Value becomes the return from interrupt()\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interrupts in tools\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "# 这明显是反模式的啊！！！怎么能把interrupt和tool的逻辑放到一起呢？\n",
    "# 我怎么对tool进行测试呢？如果我突然不想在这个工具里interrupt了呢？\n",
    "# 如果这个工具需要在其他地方被使用呢？\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str):\n",
    "    \"\"\"Send an email to a recipient.\"\"\"\n",
    "\n",
    "    # Pause before sending; payload surfaces in result[\"__interrupt__\"]\n",
    "    response = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Approve sending this email?\"\n",
    "    })\n",
    "\n",
    "    if response.get(\"action\") == \"approve\":\n",
    "        # Resume value can override inputs before executing\n",
    "        final_to = response.get(\"to\", to)\n",
    "        final_subject = response.get(\"subject\", subject)\n",
    "        final_body = response.get(\"body\", body)\n",
    "        return f\"Email sent to {final_to} with subject '{final_subject}'\"\n",
    "    return \"Email cancelled by user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validate human input\n",
    "# Sometimes you need to validate input from humans and ask again if it’s invalid. \n",
    "\n",
    "\n",
    "# 真的可以给智能体设计一种编程语言！\n",
    "# 比如我突然想到的，这个human in the loop，现在是完全做不到递归的，就是他一次只能问一个问题\n",
    "# 如果在用户回答某个问题的过程中，又有其他问题需要用户确认，就需要像现在的编程语言一样\n",
    "# 启动一个新的stack layer，但是现在的langgraph显然是做不到的\n",
    "# 这些功能越思考就越像一门编程语言！\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "def get_age_node(state: State):\n",
    "    prompt = \"What is your age?\"\n",
    "\n",
    "    while True:\n",
    "        answer = interrupt(prompt)  # payload surfaces in result[\"__interrupt__\"]\n",
    "\n",
    "        # Validate the input\n",
    "        if isinstance(answer, int) and answer > 0:\n",
    "            # Valid input - continue\n",
    "            break\n",
    "        else:\n",
    "            # Invalid input - ask again with a more specific prompt\n",
    "            prompt = f\"'{answer}' is not a valid age. Please enter a positive number.\"\n",
    "\n",
    "    return {\"age\": answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 由于langgraph的interrupt的设计缺陷，我决定不使用interrupt！\n",
    "# https://docs.langchain.com/oss/python/langgraph/interrupts#rules-of-interrupts\n",
    "# When you call interrupt within a node, LangGraph suspends execution by raising an exception that signals the runtime to pause. \n",
    "# This exception propagates up through the call stack and is caught by the runtime, \n",
    "# which notifies the graph to save the current state and wait for external input.\n",
    "\n",
    "# When execution resumes (after you provide the requested input), \n",
    "# the runtime restarts the entire node from the beginning—it does not resume from the exact line where interrupt was called.\n",
    "# This means any code that ran before the interrupt will execute again. \n",
    "# Because of this, there’s a few important rules to follow when working with interrupts to ensure they behave as expected.\n",
    "\n",
    "## Tips\n",
    "# 1. Do not wrap interrupt calls in try/except\n",
    "# 2. Do not reorder interrupt calls within a node\n",
    "# 3. Do not return complex values in interrupt calls\n",
    "# 4. Side effects called before interrupt must be idempotent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translation (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
